\section*{Problem 2: Stochastic Local Search (SLS)}

%% Uncomment the following if you need to mention formula (1):
%
% A lower bound on the number~$\lambda$ of shared elements of any pair
% among $v$~subsets of size~$r$ drawn from a given set of $b$~elements
% is given in~\cite{ASTRA:AOC}:
% \begin{equation}\label{eq:lb}
%   \text{lb}(\lambda) = 
%   \Ceiling{
%     \frac{\Ceiling{\frac{rv}{b}}^{2} ((rv) \bmod b)  +
%       \Floor{\frac{rv}{b}}^{2} (b - ((rv) \bmod b)) - rv}
%     {v(v-1)}
%   }
% \end{equation}

\paragraph{Task~A.}
\newcommand{\HyperOneSLS}{\todo{\alpha}} %% hyperparameter denoting ...
\newcommand{\HyperTwoSLS}{\todo{\beta}} %% hyperparameter denoting ...
%% You may name here even more hyperparameters
\begin{enumerate}
\item Representation.  \todo{Describe how to represent the problem:
    what are the variables, their meanings, their constraints, and the
    objective function?}
\item Initial Assignment.  \todo{Describe an algorithm for generating
  (fast) a randomised initial assignment.}
\item Move.  \todo{Describe one or more moves that go from an
  assignment to a neighbouring assignment by changing the values of
  a few variables.}
\item Constraints.  \todo{Describe for each constraint how its
  satisfaction is either algorithmically checkable efficiently or
  guaranteed to be preserved by the previous two design choices.}
\item Neighbourhood.  \todo{Describe a neighbourhood based on the
  proposed moves.
  % 
  Derive a formula for computing the size of the neighbourhood in
  terms of the problem parameters.
  % 
  Discuss whether the neighbourhood makes the search space connected,
  in the sense that every feasible assignment (that is, every
  assignment satisfying all the constraints, whether optimal or not)
  is reachable from every initial assignment (you only need to sketch
  a proof if the search space is connected, and give a counterexample
  otherwise).}
\item Cost Function.  \todo{Describe a cost function, whose value is
  to be minimised during search.}
\item Probing.  \todo{Describe how a neighbouring assignment, as
  reachable by a move, can be probed efficiently:
  % 
  describe how the cost function can be evaluated efficiently and
  incrementally, and describe the data structures used to do so.
  % 
  Give, without proof, the time complexity of probing; ideally, it is
  (sub-)linear in the problem parameters.}
\item Heuristic.  \todo{Describe a heuristic for exploring (via
    probing) the neighbourhood and selecting a neighbouring assignment
    to commit to.
  % 
  State whether the neighbourhood is explored exhaustively and, if
  so, how you determine when it was exhausted.
  % 
  Explain how you ensure that the same neighbour is not probed twice
  during a given exploration.}
\item Optimality.  \todo{Describe how you use a bound on the objective
  value in order to terminate sometimes the search with proven
  optimality, as part of the heuristic.}
\item Meta-Heuristic.  \todo{Describe a meta-heuristic based on tabu
  search: explain how the tabu list is represented; choose (a
  formula for) its size; explain how fine-grained its content is;
  and describe how it can be looked up and maintained efficiently;
  note that the tabu list is not necessarily an actual list, but
  rather a concept; make sure that worsening moves are sometimes
  made.}
\item Random Restarts.  \todo{Describe how to detect or guess
    that a random restart should be made, as part of the
    meta-heuristic.}
\item Optional Tweaks.  \todo{Describe ideas that you have
    used in order to improve your algorithm.}
\end{enumerate}
In summary, our hyperparameters (not the problem
parameters~$v$,~$b$,~$r$) are~$\HyperOneSLS$ and~$\HyperTwoSLS$.

(We are aware that we may lose points if the algorithm described above
is different from what is actually implemented in Task~B and evaluated
in Task~C.)

\paragraph{Task~B.}
We chose the high-performance programming language \todo{Java}, for
which a \todo{compiler or interpreter} is available on the Linux
computers of the IT department.  All source code is uploaded with this
report (but not listed inside it).  The compilation and running
instructions are \todo{\dots\ as follows \dots}.

We validated the correctness of our implementation by checking its
outputs on \todo{how many} instances via the provided polynomial-time
solution checker.

\paragraph{Task~C.}
All experiments were run under
%% Below is a specification of the ThinLinc Linux hosts of the IT dept:
%% --> Replace by a similar-looking specification of your used hardware
%% (under Linux, do lscpu to find the specification, and under
%% macOS, you find it via "About This Mac" in the Apple menu):
\todo{Linux Ubuntu~22.04.5 ($64$~bit) on an Intel Xeon E5520 of
  $2.27$~GHz, with $4$~processors of $4$~cores each, with a $70$~GiB
  RAM and an $8$~MiB L3 cache (a ThinLinc computer of the IT
  department).}  % barany.it.uu.se

\newcommand{\TimeoutSLS}{\todo{314.5}}  %% timeout, in CPU seconds; MIN 300.0
\newcommand{\RunsSLS}{\todo{5}}         %% independent runs per instance; MIN 5

The median runtime (in seconds), median number of steps, and median
achieved~$\lambda$ over~$\RunsSLS$ independent runs for each of the
instances of the assignment instructions are given in
Table~\ref{tab:res:sls}, for \todo{two}
%% One configuration suffices, for solo teams!
experimentally determined good configurations of values for our
hyperparameters~$\HyperOneSLS$ and~$\HyperTwoSLS$.
%
The timeout was~$\TimeoutSLS$~CPU seconds per run.

\begin{table}[t]
  \centering
  \begin{tabular}{rrrrrrrrrrr}
    & & &
    & \multicolumn{3}{c}{$\Tuple{\HyperOneSLS,\HyperTwoSLS}=\Tuple{\todo{10,5}}$}
    & \multicolumn{3}{c}{$\Tuple{\HyperOneSLS,\HyperTwoSLS}=\Tuple{\todo{20,8}}$} \\
    \cmidrule(r){5-7} \cmidrule(r){8-10}
    $v$ & $b$ & $r$ & $\text{lb}(\lambda)$
        & time & steps & $\lambda$
        & time & steps & $\lambda$ & exact \\
    \midrule
    \input{results-SLS.tex} %% Let your experiment script write directly
                            %% into this file, making sure every number
                            %% in a column has the _same_ number of decimals
  \end{tabular}
  \caption{Investment design: median runtime (in seconds), median
    number of steps, and median achieved~$\lambda$, for \todo{two}
    %% One configuration suffices, for solo teams!
    good configurations of values for our
    hyperparameters~$\HyperOneSLS$ and~$\HyperTwoSLS$,
    over~$\RunsSLS$~independent runs per instance,
    with a timeout of $\TimeoutSLS$~CPU seconds per run.
    %
    The right-most column gives the number of candidate solutions the
    outlined exact algorithm has to examine per second in order
    to match the runtime performance of the seemingly best
    configuration of values for our hyperparameters, namely
    $\Tuple{\HyperOneSLS,\HyperTwoSLS}=\Tuple{\todo{20,8}}$, if the
    instance was solved to proven optimality, and `n/a' for
    `non-applicable' otherwise.
    %% Delete the following sentence:
    \todo{(The sample performance of this skeleton table is made up!)}
    %
  }
  \label{tab:res:sls}
\end{table}

We observe that \todo{\dots\ something happened \dots}, because
\todo{\dots\ justification \dots}.

%% Optional for solo teams:
\paragraph{Task~D.}
An exact algorithm could work as follows: \todo{discuss its
  features (for instance, does it perform brute-force search?).}
%
The size of the search space of this exact algorithm is
\todo{$\binom{r!}{\cos b} \cdot \log v$}, because \todo{\dots\
  justification \dots}.

The number of candidate solutions this exact algorithm has to examine
per second in order to match the runtime performance of the seemingly
best configuration of values for our hyperparameters, according to
Task~C, of our stochastic local search algorithm is given in the
right-most column of Table~\ref{tab:res:sls}, for each instance solved
to proven optimality.
%
We think that \todo{\dots\ this is amazing \dots}, because
\todo{\dots\ justification \dots}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "assignment1-report"
%%% End:
